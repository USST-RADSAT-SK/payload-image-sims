SUPER-RESOLUTION(SR)

-This will require multiple successive images with very little time between images
-Given our camera, we could do up to four images of quick succession
-This would be a technique that we could try only after we have met our mission requirments of returning two good quatlity images of Earth
-SR works by collecting information about the imaged object from multiple images. This means that with n-images we will have an increased the total information we have gathered on the Earth. It relies on slightly different perspectives

Steps
1.) Acquire four images from CubeSense
2.) Use the Lanczos resampling method to increase the size of the images(https://en.wikipedia.org/wiki/Lanczos_resampling)
This is basically a filtering function that results in an increased image size
3.)Use sub-pixel accurate motion compensation. This basiclly merges adjacent pixels in successive images. For examples, pixel (1,245) in image one is going to be very similar to image (1,246) in image 2 due to the motion of the earth and camera. This technique will essentially average and combine the pixels that correspond to the same location on the earth. The math is a little advanced here and more research into this specific step would be required if we pursue this option. 
4.) Use spatial interpolation between the images to find values inbetween those that were recorded
5.) Compensate for the motion. I believe we would need to know the approximate rotational value of the the CubeSat to do this. I Think we would be shifting all of the pixels

Conclusions
I think that this could be a good option for our team. Although some of the math may be a little intense, we could likely use many built in functions in matlab or python to assist with this. We should consider this option. Click on the link at the bottom of the page to see an example of how four images can be used to improve resolution. 

http://www.infognition.com/articles/what_is_super_resolution.html




Single Image Super-Resolution Using Deep Learning

-Uses only a single image and Matlab deep learning  & image processing toolbox functions
-Trains 'Very Deep Super Resolution' neural network using large set of given images at high and low resolution (image set is provided in link below).
-Neural network then learns to estimate the differences between high and low resolution images from a single low-res image and creates a high resolution image

Steps
1) Take single image
2) Use method & image set given in linked Mathworks source below to train network. Network is essentially a series of many cascaded convolutional filters that finds the details lost between high and low resolution images and learns to estimate what detail has been lost, which can then be added back to a low resolution image. Source provides extensive documentation on implementation, and Matlab deep learning toolbox gives many helper functions. 
3) Upscale low res image using bicubic interpolation (built in to imresize function in Matlab) or any other method so that low-res image is desired size
4) Pass upscaled low res image into network, which returns high resolution image


Conclusion
Fairly complicated method, but results look good and the link below has very in depth instructions with code and explanations that completely lays out how to utilize this method. Mathworks also has in depth documentation on all the functions in the deep learning toolbox. Not sure how the results would compare to other methods that use multiple images. Could be worth using if we run into any difficulty capturing multiple similar images. 

https://www.mathworks.com/help/images/single-image-super-resolution-using-deep-learning.html